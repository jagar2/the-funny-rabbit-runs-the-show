{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# You must make sure to run all cells in sequence using shift + enter or you might encounter errors\n",
    "from pykubegrader.initialize import initialize_assignment\n",
    "\n",
    "responses = initialize_assignment(\"1_practice_quiz_data_types_q\", \"week_2\", \"practicequiz\", assignment_points = 14.5, assignment_tag = 'week2-practicequiz')\n",
    "\n",
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"1_practice_quiz_data_types_q.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# â“ Python Basics: Data Structures and Types Quiz ðŸ\n",
    "\n",
    "![Python Quiz](./assets/figures/python-string-practice-quiz.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_practice_quiz_data_types_q import Question1\n",
    "Question1().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_practice_quiz_data_types_q import Question2\n",
    "Question2().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_practice_quiz_data_types_q import Question3\n",
    "Question3().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Wastewater Treatment Analysis ðŸŒŠ\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "Create a Python dictionary to analyze wastewater treatment data. Your solution must include:\n",
    "\n",
    "1. Create a dictionary named `treatment_data` with these EXACT keys and values:\n",
    "   - `facility`: String \"Plant-2000\"\n",
    "   - `capacity`: Float 2.0\n",
    "   - `test_ph_levels`: List [6.8, 7.2, 7.1, 7.4, 6.9]\n",
    "   - `performance_metrics`: Dictionary containing:\n",
    "     - `flow_rate`: Float 185.5\n",
    "     - `efficiency`: Float 92.8  # percent\n",
    "\n",
    "2. Calculate these values (store each in its own variable):\n",
    "   - `avg_ph`: Average of test_ph_levels (use `sum` and `len`)\n",
    "   - `max_ph`: Maximum pH from test_ph_levels (use `max`)\n",
    "   - `capacity_utilization`: Flow rate divided by capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the treatment data dictionary with exact values\n",
    "...\n",
    "\n",
    "\n",
    "# Calculate required values\n",
    "...\n",
    "\n",
    "# We have provided the code to print the results for you\n",
    "# Print results for verification (optional but helpful)\n",
    "print(f\"Average pH: {avg_ph:.1f}\")\n",
    "print(f\"Maximum pH: {max_ph}\")\n",
    "print(f\"Capacity Utilization: {capacity_utilization:.1f} L/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"question-Wastewater-Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Submitting Assignment\n",
    "\n",
    "Please run the following block of code using `shift + enter` to submit your assignment, you should see your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.submit.submit_assignment import submit_assignment\n",
    "\n",
    "submit_assignment(\"week2-practicequiz\", \"1_practice_quiz_data_types_q\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engr131_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "question-Wastewater-Data": {
     "name": "question-Wastewater-Data",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> max_question_points = str(6.5)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(6.5)\n>>> log_variable('total-points', f'Reading-Week-X, 1_practice_quiz_data_types_q', 6.5)\n>>> question_id = 'question-Wastewater-Data-1'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, isinstance(treatment_data, dict))\n>>> assert isinstance(treatment_data, dict), 'treatment_data must be a dictionary'\n>>> if isinstance(treatment_data, dict):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Not a dictionary - make sure you create treatment_data as a dictionary",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Dictionary type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-2'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(treatment_data['facility'])))\n>>> assert isinstance(treatment_data['facility'], str), 'facility must be a string'\n>>> if isinstance(treatment_data['facility'], str):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'facility' value must be a string (str)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Facility data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-3'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(treatment_data['capacity'])))\n>>> assert isinstance(treatment_data['capacity'], float), 'capacity must be a float'\n>>> if isinstance(treatment_data['capacity'], float):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'capacity' value must be a float (not an int)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Capacity data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-4'\n>>> max_score = 0.5\n>>> score = 0\n>>> assert isinstance(treatment_data['test_ph_levels'], list), 'test_ph_levels must be a list'\n>>> if isinstance(treatment_data['test_ph_levels'], list):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'test_ph_levels' value must be a list",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Test pH levels data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-5'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(treatment_data['performance_metrics'])))\n>>> assert isinstance(treatment_data['performance_metrics'], dict), 'performance_metrics must be a dictionary'\n>>> if isinstance(treatment_data['performance_metrics'], dict):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'performance_metrics' value must be a dictionary",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Performance metrics data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-6'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, treatment_data['facility'])\n>>> assert treatment_data['facility'] == 'Plant-2000', \"facility must be exactly 'Plant-2000'\"\n>>> if treatment_data['facility'] == 'Plant-2000':\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The facility must be exactly 'Plant-2000' (check spelling and capitalization)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Facility value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-7'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, abs(treatment_data['capacity'] - 2.0))\n>>> assert abs(treatment_data['capacity'] - 2.0) < 0.001, 'capacity must be exactly 2.0'\n>>> if abs(treatment_data['capacity'] - 2.0) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The capacity must be exactly 2.0 (as a float)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Capacity value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-8'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, treatment_data['test_ph_levels'])\n>>> conditional = treatment_data['test_ph_levels'] == [6.8, 7.2, 7.1, 7.4, 6.9]\n>>> assert conditional, 'test_ph_levels must match exactly'\n>>> if conditional:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The test_ph_levels list must be exactly [6.8, 7.2, 7.1, 7.4, 6.9]",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Test pH levels list is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-9'\n>>> max_score = 0.5\n>>> score = 0\n>>> assert abs(treatment_data['performance_metrics']['flow_rate'] - 185.5) < 0.001, 'flow_rate must be exactly 185.5'\n>>> if abs(treatment_data['performance_metrics']['flow_rate'] - 185.5) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The flow_rate must be exactly 185.5 (as a float)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Flow rate value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-10'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, abs(treatment_data['performance_metrics']['efficiency']))\n>>> assert abs(treatment_data['performance_metrics']['efficiency'] - 92.8) < 0.001, 'efficiency must be exactly 92.8'\n>>> if abs(treatment_data['performance_metrics']['efficiency'] - 92.8) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The efficiency must be exactly 92.8 (as a float)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Efficiency value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-11'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, avg_ph)\n>>> assert isinstance(avg_ph, float), 'avg_ph must be a float'\n>>> assert abs(avg_ph - 7.08) < 0.001, 'avg_ph calculation incorrect - should be 7.08'\n>>> if isinstance(avg_ph, float) and abs(avg_ph - 7.08) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "avg_ph must be a float type (use division with sum and len)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Average pH data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-12'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, max_ph)\n>>> assert isinstance(max_ph, float), 'max_ph must be a float'\n>>> assert max_ph == 7.4, 'max_ph calculation incorrect - should be 7.4'\n>>> if isinstance(max_ph, float) and max_ph == 7.4:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "max_ph must be a float with value 7.4 (use max() function)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Maximum pH data type and value are correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Wastewater-Data-13'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, capacity_utilization)\n>>> assert isinstance(capacity_utilization, float), 'capacity_utilization must be a float'\n>>> assert abs(capacity_utilization - 92.75) < 0.1, 'capacity_utilization calculation incorrect - should be 92.75'\n>>> if isinstance(capacity_utilization, float) and abs(capacity_utilization - 92.75) < 0.1:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_quiz_data_types_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "capacity_utilization must be a float equal to 92.75 (flow_rate/capacity)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Capacity utilization calculation is correct"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
