{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# You must make sure to run all cells in sequence using shift + enter or you might encounter errors\n",
    "from pykubegrader.initialize import initialize_assignment\n",
    "\n",
    "responses = initialize_assignment(\"1_homework\", \"week_2\", \"homework\", assignment_points = 57.75, assignment_tag = 'week2-homework')\n",
    "\n",
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"1_homework.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# üè† Python Programming: Explore the Nutshell Studies üïµÔ∏è‚Äç‚ôÄÔ∏èüîç\n",
    "\n",
    "<iframe width=\"1536\" height=\"864\" src=\"https://www.youtube.com/embed/2-6ndwvK3UI\" title=\"Murder Is Her Hobby: Frances Glessner Lee and The Nutshell Studies of Unexplained Death\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "The Nutshell Studies of Unexplained Death were created by Frances Glessner Lee as miniature dioramas replicating real crime scenes. These models are used to train investigators in observing details, solving mysteries, and analyzing evidence.  \n",
    "\n",
    "![](./assets/figures/francis.png) \n",
    "\n",
    "In these Python exercises, you'll recreate parts of this fascinating process by solving problems involving data types, numerical precision, lists, dictionaries, and basic calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1: Scaling the Mystery üßÆüìè\n",
    "\n",
    "![](./assets/figures/nutshell-1.jpg)\n",
    "\n",
    "\"Everything must be scaled to perfection!\"\n",
    "\n",
    "The Nutshell Studies require precise scaling to recreate scenes. You are given:\n",
    "- The real room width is 15.5 feet.\n",
    "- The model room width is given as a string: `\"4.25\"` inches.\n",
    "\n",
    "#### Tasks:\n",
    "1. Convert the room width and length to inches. Save the results in variables `room_width_inches` and `room_length_inches`.\n",
    "2. Convert the variable `model_width` to a float, replace the original variable. To do this you should use the `float()` function.\n",
    "3. Calculate the scale ratio by dividing the model width by the room width. Save the result in a variable `scale_ratio`.\n",
    "4. Calculate the real-world area:\n",
    "   - Compute the real-world area of the rectangular room using the formula:  \n",
    "     $$\n",
    "     \\text{Real-world area} = \\text{width (in feet)} \\times \\text{length (in feet)}\n",
    "     $$\n",
    "   - This will give the area in square feet.\n",
    "   - Save the result in a variable `real_area_sqft`.\n",
    "\n",
    "5. Calculate the scaled diorama area:\n",
    "   - First, calculate the area of the real room in square inches by using the width and length in inches and multiplying them.\n",
    "   - Scale this area down using the square of the scale ratio:  \n",
    "     \n",
    "     $$\n",
    "     \\text{Scaled diorama area} = \\frac{\\text{Real area (in square inches)}}{(\\text{scale ratio})^2}\n",
    "     $$\n",
    "     \n",
    "  - Save the result in a variable `scaled_area_sqin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "def question_1():\n",
    "    # Given information\n",
    "    # Room dimensions\n",
    "    room_width_feet = 15.5  # Real room width in feet\n",
    "    room_length_feet = 20   # Real room length in feet\n",
    "    model_width = \"4.25\"  # Model width as a string\n",
    "\n",
    "    # Convert dimensions to inches for consistency\n",
    "    ...\n",
    "\n",
    "    # Convert the model width to a float\n",
    "    ...\n",
    "\n",
    "    # Calculate the scale ratio\n",
    "    ...\n",
    "\n",
    "    # Real-world area (in square feet) and scaled diorama area (in square inches)\n",
    "    ...\n",
    "\n",
    "    return room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin\n",
    "\n",
    "\n",
    "# We have provided this code for you to test your implementation\n",
    "room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n",
    "\n",
    "# Print results\n",
    "print(f\"Scale of the model: {scale_ratio:.6f}\")\n",
    "print(f\"Real-world area: {real_area_sqft:.2f} square feet\")\n",
    "print(f\"Scaled diorama area: {scaled_area_sqin:.2f} square inches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"scaling-the-mystery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2: Cataloging Crime Scene Objects üìùüî™\n",
    "\n",
    "![](./assets/figures/nutshell-2.jpg)\n",
    "\n",
    "\"What‚Äôs in the crime scene?\"\n",
    "\n",
    "A crime scene contains various objects: `\"knife\"`, `\"glass\"`, `\"rug\"`, `\"chair\"`, and `\"lamp\"`.  \n",
    "To investigate, you'll need to create and modify a list.\n",
    "\n",
    "#### Tasks:\n",
    "1. Build a list of object, `objects`, containing the objects mentioned above. \n",
    "    - make sure to add a comment saying `List of objects found at the crime scene`.\n",
    "2. Add three more objects: `\"hat\"`, `\"pen\"`, `\"rope\"`.\n",
    "    - There are several ways to add items to a list. You can use the `append()` method or the `+` operator.\n",
    "\n",
    "\n",
    "3. Calculate the number of objects at the crime scene and save the result in a variable `total_objects`. To do this, use the `len()` function.\n",
    "\n",
    "3. Retrieve and print the 3rd, 5th, and last objects from the list.\n",
    "    - Retrieve the third object and assign it to the variable `third_object`.\n",
    "    - Retrieve the fifth object and assign it to the variable `fifth_object`.\n",
    "    - Retrieve the last object and assign it to the variable `last_object`. Make sure this will always get the last object, regardless of the number of objects in the list, by using the index `-1`.\n",
    "\n",
    "4. Write the code to print information: \n",
    "    - The updated list of objects, \"Updated list of objects: [list of objects]\".\n",
    "    - The total number of objects, \"Total number of objects: [total_objects]\".\n",
    "    - The third object, \"3rd object: [third_object]\".\n",
    "    - The fifth object, \"5th object: [fifth_object]\".\n",
    "    - The last object, \"Last object: [last_object]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "def question_2():\n",
    "    # List of objects in the crime scene\n",
    "    # Build a list of object, `objects`, with the following objects: \"knife\", \"glass\", \"rug\", \"chair\", \"lamp\"\n",
    "    ...\n",
    "\n",
    "    # Add three more objects: `\"hat\"`, `\"pen\"`, `\"rope\"`.\n",
    "    ...\n",
    "\n",
    "    # Calculate the total number of objects using the `len()` function\n",
    "    ...\n",
    "\n",
    "    # Retrieve specific objects\n",
    "\n",
    "    # Retrieve the third object and assign it to the variable `third_object`.\n",
    "    ...\n",
    "\n",
    "    # Retrieve the fifth object and assign it to the variable `fifth_object`.\n",
    "    ...\n",
    "\n",
    "    # Retrieve the last object and assign it to the variable `last_object`.\n",
    "    ...\n",
    "        \n",
    "    # The updated list of objects, \"Updated list of objects: [list of objects]\". \n",
    "    ...\n",
    "\n",
    "    # The total number of objects, \"Total number of objects: [total_objects]\".\n",
    "    ...\n",
    "\n",
    "    # The third object, \"3rd object: [third_object]\".\n",
    "    ...\n",
    "\n",
    "    # The fifth object, \"5th object: [fifth_object]\".\n",
    "    ...\n",
    "\n",
    "    # The last object, \"Last object: [last_object]\".\n",
    "    ...\n",
    "    \n",
    "    return objects, total_objects, third_object, fifth_object, last_object\n",
    "\n",
    "objects, total_objects, third_object, fifth_object, last_object = question_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"cataloging-crime-scenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 3: Object Details Dictionary üóÇÔ∏èüîç\n",
    "\n",
    "![](./assets/figures/nutshell-3.jpg)\n",
    "\n",
    "\"Track every detail!\"\n",
    "\n",
    "Each object in the Nutshell diorama has attributes like its position, whether it‚Äôs a clue, and its priority for solving the case.\n",
    "\n",
    "### Tasks:\n",
    "1. Create a dictionary `objects_details` with the following details (this should be a nested dictionary):\n",
    "   - knife: position = `\"near victim's hand\"`, is_clue = `True`, priority = `8`\n",
    "   - glass: position = `\"on the table\"`, is_clue = `False`, priority = `3`\n",
    "   - rug: position = `\"center of the room\"`, is_clue = `False`, priority = `2`\n",
    "   - lamp: position = `\"overturned near the corner\"`, is_clue = `True`, priority = `6`\n",
    "2. Update the priority of `\"glass\"` to `7`.  \n",
    "3. Retrieve and print the position and priority of the `\"knife\"` and `\"rug\"`. Save the knife position and priority in variables `knife_position` and `knife_priority`, and the rug position and priority in variables `rug_position` and `rug_priority`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def question_3():\n",
    "    # Dictionary of objects with details\n",
    "    #     1. Create a dictionary with the following details (this should be a nested dictionary):\n",
    "    #    - **knife**: position = `\"near victim's hand\"`, is_clue = `True`, priority = `8`\n",
    "    #    - **glass**: position = `\"on the table\"`, is_clue = `False`, priority = `3`\n",
    "    #    - **rug**: position = `\"center of the room\"`, is_clue = `False`, priority = `2`\n",
    "    #    - **lamp**: position = `\"overturned near the corner\"`, is_clue = `True`, priority = `6`\n",
    "    ...\n",
    "\n",
    "    # Do not modify this code, it is used for grading\n",
    "    original_details = copy.deepcopy(objects_details)\n",
    "\n",
    "    # Update the priority of the \"glass\"\n",
    "    # 2. Update the **priority** of `\"glass\"` to `7`.\n",
    "    ...\n",
    "\n",
    "    # Retrieve details for \"knife\" and \"rug\"\n",
    "    # 3. Retrieve and print the **position** and **priority** of the `\"knife\"` and `\"rug\"`.\n",
    "    # Save the knife position and priority in variables `knife_position` and `knife_priority`,\n",
    "    # and the rug position and priority in variables `rug_position` and `rug_priority`.\n",
    "    ...\n",
    "    \n",
    "    return (\n",
    "        original_details, \n",
    "        objects_details,\n",
    "        knife_position,\n",
    "        knife_priority,\n",
    "        rug_position,\n",
    "        rug_priority,\n",
    "    )\n",
    "\n",
    "original_details, objects_details, knife_position, knife_priority, rug_position, rug_priority = question_3()\n",
    "\n",
    "# Print results\n",
    "print(\"Updated dictionary:\", objects_details)\n",
    "print(\"\\nDetails of knife:\")\n",
    "print(\"Position:\", knife_position)\n",
    "print(\"Priority:\", knife_priority)\n",
    "print(\"\\nDetails of rug:\")\n",
    "print(\"Position:\", rug_position)\n",
    "print(\"Priority:\", rug_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"Object-Details-Dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Bonus Challenge: Handling Missing Objects üïµÔ∏è‚Äç‚ôÇÔ∏è‚ùì\n",
    "\n",
    "![](./assets/figures/nutshell-4.webp)\n",
    "\n",
    "The investigators occasionally encounter missing data for certain objects in the crime scene. Use dictionary methods like `.get()` to safely handle cases where some objects might not exist in the dictionary.\n",
    "\n",
    "### Scenario:\n",
    "The following objects and their priority scores are provided:\n",
    "- knife: priority = 8\n",
    "- glass: priority = 7\n",
    "- rug: priority = 2\n",
    "- lamp: priority = 6\n",
    "\n",
    "An investigator asks about the priority of the following objects:\n",
    "1. knife\n",
    "2. hat (not in the dictionary)\n",
    "3. rug\n",
    "4. book (not in the dictionary)\n",
    "\n",
    "### Tasks:\n",
    "1. Use the `.get()` method to retrieve the priorities of the requested objects.  \n",
    "2. Assign a default priority of `0` for any objects not found in the dictionary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "def bonus():\n",
    "\n",
    "    # Dictionary of objects with their priority scores\n",
    "    priority_scores = {\n",
    "        \"knife\": 8,\n",
    "        \"glass\": 7,\n",
    "        \"rug\": 2,\n",
    "        \"lamp\": 6\n",
    "    }\n",
    "\n",
    "    # Use the `.get()` method to safely retrieve priorities, with a default value of 0 for missing objects\n",
    "    # Save the retrieved priorities in variables knife_priority, hat_priority, rug_priority, and book_priority\n",
    "    ...\n",
    "    \n",
    "    return knife_priority, hat_priority, rug_priority, book_priority\n",
    "\n",
    "knife_priority, hat_priority, rug_priority, book_priority = bonus()\n",
    "\n",
    "# Print the retrieved priorities\n",
    "print(\"Retrieved priority scores:\")\n",
    "print(f\"Knife: {knife_priority}\")\n",
    "print(f\"Hat: {hat_priority}\")\n",
    "print(f\"Rug: {rug_priority}\")\n",
    "print(f\"Book: {book_priority}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"handeling-missing-objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\n",
    "    \"https://americanart.si.edu/exhibitions/nutshells/inside\",\n",
    "    width=800,\n",
    "    height=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Submitting Assignment\n",
    "\n",
    "Please run the following block of code using `shift + enter` to submit your assignment, you should see your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.submit.submit_assignment import submit_assignment\n",
    "\n",
    "submit_assignment(\"week2-homework\", \"1_homework\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engr131_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "Object-Details-Dictionary": {
     "name": "Object-Details-Dictionary",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> max_question_points = str(14.0)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(57.75)\n>>> log_variable('total-points', f'Reading-Week-X, 1_homework', 57.75)\n>>> question_id = 'Object-Details-Dictionary-1'\n>>> max_score = 2.0\n>>> score = 0\n>>> responses = update_responses(question_id, original_details)\n>>> original_details, _, _, _, _, _ = question_3()\n>>> expected_keys = {'knife', 'glass', 'rug', 'lamp'}\n>>> actual_keys = {key.strip().lower() for key in original_details.keys()}\n>>> assert expected_keys == actual_keys, f'Expected dictionary keys: {expected_keys}, but got: {actual_keys}.'\n>>> expected_original_details = {'knife': {'position': \"near victim's hand\", 'is_clue': True, 'priority': 8}, 'glass': {'position': 'on the table', 'is_clue': False, 'priority': 3}, 'rug': {'position': 'center of the room', 'is_clue': False, 'priority': 2}, 'lamp': {'position': 'overturned near the corner', 'is_clue': True, 'priority': 6}}\n>>> assert original_details == expected_original_details, 'The original dictionary is incorrect.'\n>>> if expected_keys == actual_keys and original_details == expected_original_details:\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The dictionary structure is incorrect or missing required keys.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "The initial dictionary is correctly structured and initialized."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-2'\n>>> max_score = 2.0\n>>> score = 0\n>>> responses = update_responses(question_id, objects_details['glass']['priority'])\n>>> _, objects_details, _, _, _, _ = question_3()\n>>> glass_priority = objects_details['glass']['priority']\n>>> assert glass_priority == 7, \"The priority of 'glass' should be updated to 7.\"\n>>> if glass_priority == 7:\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"glass\" was not correctly updated to 7.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "The priority of \"glass\" is correctly updated to 7."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-3'\n>>> max_score = 2.0\n>>> score = 0\n>>> responses = update_responses(question_id, knife_position)\n>>> _, _, knife_position, _, _, _ = question_3()\n>>> expected_knife_position = \"near victim's hand\"\n>>> assert knife_position.strip().lower() == expected_knife_position.strip().lower(), \"The position of 'knife' is incorrect.\"\n>>> if knife_position.strip().lower() == expected_knife_position.strip().lower():\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The position of \"knife\" is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "The position of \"knife\" is correctly retrieved."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-4'\n>>> max_score = 2.0\n>>> score = 0\n>>> responses = update_responses(question_id, knife_priority)\n>>> _, _, _, knife_priority, _, _ = question_3()\n>>> expected_knife_priority = 8\n>>> assert knife_priority == expected_knife_priority, \"The priority of 'knife' is incorrect.\"\n>>> if knife_priority == expected_knife_priority:\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"knife\" is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "The priority of \"knife\" is correctly retrieved."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-5'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, rug_position)\n>>> _, _, _, _, rug_position, _ = question_3()\n>>> expected_rug_position = 'center of the room'\n>>> assert rug_position.strip().lower() == expected_rug_position.strip().lower(), \"The position of 'rug' is incorrect.\"\n>>> if rug_position.strip().lower() == expected_rug_position.strip().lower():\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The position of \"rug\" is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The position of \"rug\" is correctly retrieved."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-6'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, rug_priority)\n>>> _, _, _, _, _, rug_priority = question_3()\n>>> expected_rug_priority = 2\n>>> assert rug_priority == expected_rug_priority, \"The priority of 'rug' is incorrect.\"\n>>> if rug_priority == expected_rug_priority:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"rug\" is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The priority of \"rug\" is correctly retrieved."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-7'\n>>> max_score = 3.0\n>>> score = 0\n>>> responses = update_responses(question_id, objects_details)\n>>> _, objects_details, _, _, _, _ = question_3()\n>>> expected_final_objects_details = {'knife': {'position': \"near victim's hand\", 'is_clue': True, 'priority': 8}, 'glass': {'position': 'on the table', 'is_clue': False, 'priority': 7}, 'rug': {'position': 'center of the room', 'is_clue': False, 'priority': 2}, 'lamp': {'position': 'overturned near the corner', 'is_clue': True, 'priority': 6}}\n>>> assert objects_details == expected_final_objects_details, 'The final dictionary structure is incorrect after updates.'\n>>> if objects_details == expected_final_objects_details:\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The final dictionary structure is incorrect after updates.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "The final dictionary structure is correct after updates."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "cataloging-crime-scenes": {
     "name": "cataloging-crime-scenes",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import re\n>>> import inspect\n>>> max_question_points = str(25.25)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(57.75)\n>>> log_variable('total-points', f'Reading-Week-X, 1_homework', 57.75)\n>>> question_id = 'cataloging-crime-scenes-1'\n>>> max_score = 3.5\n>>> score = 0\n>>> function_source = inspect.getsource(question_2)\n>>> condition = 'len(' in function_source\n>>> assert condition, 'The `len()` function is not used to calculate the total number of objects.'\n>>> condition_2 = '[-1]' in function_source\n>>> assert condition_2, 'The `[-1]` indexing is not used to retrieve the last object.'\n>>> if condition and condition_2:\n...     score = 3.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Required methods (len() and [-1]) are missing in the implementation.",
         "hidden": false,
         "locked": false,
         "points": 3.5,
         "success_message": "The required methods (len() and [-1]) are used in the implementation."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> question_id = 'cataloging-crime-scenes-2'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> objects, _, _, _, _ = question_2()\n>>> sys.output = sys.__stdout__\n>>> condition = 'knife' in objects and 'glass' in objects and ('rug' in objects) and ('chair' in objects) and ('lamp' in objects)\n>>> assert condition, 'The initial list is incorrect.'\n>>> if condition:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The initial list of objects is missing or incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The initial list of objects is created correctly."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> question_id = 'cataloging-crime-scenes-3'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> objects, _, _, _, _ = question_2()\n>>> sys.stdout = sys.__stdout__\n>>> condition = 'hat' in objects and 'pen' in objects and ('rope' in objects)\n>>> assert condition, 'New objects were not added correctly.'\n>>> if condition:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The new objects are not added correctly.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "New objects are added correctly to the list."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> question_id = 'cataloging-crime-scenes-4'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> _, total_objects, _, _, _ = question_2()\n>>> sys.stdout = sys.__stdout__\n>>> assert total_objects == 8, f'Total objects should be 8, but got {total_objects}.'\n>>> if total_objects == 8:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The total number of objects is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The total number of objects is calculated correctly."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> question_id = 'cataloging-crime-scenes-5'\n>>> max_score = 3.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> _, _, third_object, fifth_object, last_object = question_2()\n>>> sys.stdout = sys.__stdout__\n>>> assert third_object == 'rug', f\"The third object should be 'rug', but got {third_object}.\"\n>>> assert fifth_object == 'lamp', f\"The fifth object should be 'lamp', but got {fifth_object}.\"\n>>> assert last_object == 'rope', f\"The last object should be 'rope', but got {last_object}.\"\n>>> if third_object == 'rug' and fifth_object == 'lamp' and (last_object == 'rope'):\n...     score = 3.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Retrieval of specific objects is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 3.5,
         "success_message": "Retrieval of specific objects is correct."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import io\n>>> import sys\n>>> question_id = 'cataloging-crime-scenes-6'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> question_2()\n>>> sys.stdout = sys.__stdout__\n>>> output_str = output.getvalue()\n>>> condition1 = 'Updated list of objects:' in output_str\n>>> condition2 = 'Total number of objects: 8' in output_str\n>>> condition3 = '3rd object: rug' in output_str\n>>> condition4 = '5th object: lamp' in output_str\n>>> condition5 = 'Last object: rope' in output_str\n>>> assert condition1, 'The updated list of objects is not printed correctly.'\n>>> assert condition2, 'The total number of objects is not printed correctly.'\n>>> assert condition3, 'The third object is not printed correctly.'\n>>> assert condition4, 'The fifth object is not printed correctly.'\n>>> assert condition5, 'The last object is not printed correctly.'\n>>> if condition1 and condition2 and condition3 and condition4 and condition5:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The printed outputs are incorrect or missing.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The printed outputs are formatted correctly."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import re\n>>> import inspect\n>>> question_id = 'cataloging-crime-scenes-7'\n>>> max_score = 1.5\n>>> score = 0\n>>> function_source = inspect.getsource(question_2)\n>>> condition = 'append(' in function_source or '+' in function_source\n>>> assert condition, 'The `append()` method or `+` operator is not used to add items to the list.'\n>>> if condition:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The method for adding items (`append()` or `+`) is missing or incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The required methods for adding items (`append()` or `+`) are used correctly."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import re\n>>> import inspect\n>>> question_id = 'cataloging-crime-scenes-8'\n>>> max_score = 9.25\n>>> score = 0\n>>> function_source = inspect.getsource(question_2)\n>>> updated_list_regex = 'print\\\\(\\\\s*f?[\\'\\\\\"]Updated list of objects[:]?.*?(\\\\{?objects\\\\}?)?[\\'\\\\\"]\\\\s*(,\\\\s*objects\\\\s*)?\\\\)'\n>>> total_objects_regex = 'print\\\\(\\\\s*f?[\\'\\\\\"]Total number of objects[:]?.*?(\\\\{?total_objects\\\\}?)?[\\'\\\\\"]\\\\s*(,\\\\s*total_objects\\\\s*)?\\\\)'\n>>> third_object_regex = 'print\\\\(\\\\s*f?[\\'\\\\\"]3rd object[:]?.*?(\\\\{?third_object\\\\}?)?[\\'\\\\\"]\\\\s*(,\\\\s*third_object\\\\s*)?\\\\)'\n>>> fifth_object_regex = 'print\\\\(\\\\s*f?[\\'\\\\\"]5th object[:]?.*?(\\\\{?fifth_object\\\\}?)?[\\'\\\\\"]\\\\s*(,\\\\s*fifth_object\\\\s*)?\\\\)'\n>>> last_object_regex = 'print\\\\(\\\\s*f?[\\'\\\\\"]Last object[:]?.*?(\\\\{?last_object\\\\}?)?[\\'\\\\\"]\\\\s*(,\\\\s*last_object\\\\s*)?\\\\)'\n>>> condition_1 = re.search(updated_list_regex, function_source)\n>>> condition_2 = re.search(total_objects_regex, function_source)\n>>> condition_3 = re.search(third_object_regex, function_source)\n>>> condition_4 = re.search(fifth_object_regex, function_source)\n>>> condition_5 = re.search(last_object_regex, function_source)\n>>> assert condition_1, 'The print statement for the updated list is hard-coded.'\n>>> assert condition_2, 'The print statement for the total number of objects is hard-coded.'\n>>> assert condition_3, 'The print statement for the third object is hard-coded.'\n>>> assert condition_4, 'The print statement for the fifth object is hard-coded.'\n>>> assert condition_5, 'The print statement for the last object is hard-coded.'\n>>> if condition_1 and condition_2 and condition_3 and condition_4 and condition_5:\n...     score = 9.25\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The print statements are hard-coded instead of dynamically generated.",
         "hidden": false,
         "locked": false,
         "points": 9.25,
         "success_message": "The print statements are dynamically generated and not hard-coded."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import re\n>>> import inspect\n>>> question_id = 'cataloging-crime-scenes-9'\n>>> max_score = 1.5\n>>> score = 0\n>>> function_source = inspect.getsource(question_2)\n>>> hard_coded_list_regex = 'objects\\\\s*=\\\\s*\\\\[\\\\s*[\\'\\\\\"]knife[\\'\\\\\"],\\\\s*[\\'\\\\\"]glass[\\'\\\\\"],\\\\s*[\\'\\\\\"]rug[\\'\\\\\"],\\\\s*[\\'\\\\\"]chair[\\'\\\\\"],\\\\s*[\\'\\\\\"]lamp[\\'\\\\\"],\\\\s*[\\'\\\\\"]hat[\\'\\\\\"],\\\\s*[\\'\\\\\"]pen[\\'\\\\\"],\\\\s*[\\'\\\\\"]rope[\\'\\\\\"]\\\\s*\\\\]'\n>>> condition = not re.search(hard_coded_list_regex, function_source)\n>>> assert condition, 'The list of objects is hard-coded in the function. Please ensure the list is dynamically constructed using methods like concatenation (`+`) or `append()`.'\n>>> if condition:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The list values are hard-coded in the function instead of being dynamically generated.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The full list is dynamically generated and not hard-coded."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "handeling-missing-objects": {
     "name": "handeling-missing-objects",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> max_question_points = str(5.0)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(57.75)\n>>> log_variable('total-points', f'Reading-Week-X, 1_homework', 57.75)\n>>> question_id = 'handeling-missing-objects-1'\n>>> max_score = 1.0\n>>> score = 0\n>>> responses = update_responses(question_id, knife_priority)\n>>> knife_priority, _, _, _ = bonus()\n>>> assert knife_priority == 8, \"The priority of 'knife' should be 8.\"\n>>> if knife_priority == 8:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"knife\" is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "The priority of \"knife\" is correctly retrieved."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'handeling-missing-objects-2'\n>>> max_score = 1.0\n>>> score = 0\n>>> responses = update_responses(question_id, hat_priority)\n>>> _, hat_priority, _, _ = bonus()\n>>> assert hat_priority == 0, \"The priority of 'hat' should default to 0.\"\n>>> if hat_priority == 0:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"hat\" should default to 0 when missing.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "The default priority of \"hat\" is correctly set to 0."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'handeling-missing-objects-3'\n>>> max_score = 1.0\n>>> score = 0\n>>> responses = update_responses(question_id, rug_priority)\n>>> _, _, rug_priority, _ = bonus()\n>>> assert rug_priority == 2, \"The priority of 'rug' should be 2.\"\n>>> if rug_priority == 2:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"rug\" is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "The priority of \"rug\" is correctly retrieved."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'handeling-missing-objects-4'\n>>> max_score = 1.0\n>>> score = 0\n>>> responses = update_responses(question_id, book_priority)\n>>> _, _, _, book_priority = bonus()\n>>> assert book_priority == 0, \"The priority of 'book' should default to 0.\"\n>>> if book_priority == 0:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"book\" should default to 0 when missing.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "The default priority of \"book\" is correctly set to 0."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import re\n>>> import inspect\n>>> question_id = 'handeling-missing-objects-5'\n>>> max_score = 1.0\n>>> score = 0\n>>> function_source = inspect.getsource(bonus)\n>>> get_usage = re.findall('priority_scores\\\\.get\\\\(', function_source)\n>>> res_get_usage = len(get_usage) >= 4\n>>> assert res_get_usage, 'The function should use the `.get()` method for each object, with a default value for missing objects.'\n>>> if res_get_usage:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The function does not correctly use the `.get()` method for safe retrieval.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "The function uses the `.get()` method correctly to handle missing keys."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "scaling-the-mystery": {
     "name": "scaling-the-mystery",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> max_question_points = str(13.5)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(57.75)\n>>> log_variable('total-points', f'Reading-Week-X, 1_homework', 57.75)\n>>> question_id = 'scaling-the-mystery-1'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(model_width)))\n>>> responses = update_responses(question_id, model_width)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> modal_width_float = isinstance(model_width, float)\n>>> assert modal_width_float, 'model_width must be a float'\n>>> assert model_width == 4.25, 'model_width value should be 4.25 after conversion'\n>>> if modal_width_float and model_width == 4.25:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The model width string must be converted to a float.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The model width string is correctly converted to a float."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-2'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, room_width_inches)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_room_width_inches = 15.5 * 12\n>>> assert room_width_inches == expected_room_width_inches, 'room_width_inches value is incorrect'\n>>> if room_width_inches == expected_room_width_inches:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real room width conversion to inches is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "Real room width is correctly converted to inches."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import re\n>>> import inspect\n>>> question_id = 'scaling-the-mystery-3'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, room_width_inches)\n>>> function_source = inspect.getsource(question_1)\n>>> condition = re.findall('.*float\\\\(model_width\\\\).*', function_source)\n>>> assert condition, 'You must convert the model width to a float, using the float() function.'\n>>> if condition:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The model width string must be converted to a float.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The model width string is correctly converted to a float."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-4'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, room_length_inches)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_room_length_inches = 20 * 12\n>>> assert room_length_inches == expected_room_length_inches, 'room_length_inches value is incorrect'\n>>> if room_length_inches == expected_room_length_inches:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real room length conversion to inches is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "Real room length is correctly converted to inches."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-5'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scale_ratio)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_scale_ratio = 4.25 / (15.5 * 12)\n>>> assert scale_ratio == expected_scale_ratio, 'scale_ratio value is incorrect'\n>>> if scale_ratio == expected_scale_ratio:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The scale ratio calculation is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The scale ratio is correctly calculated."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-6'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, real_area_sqft)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_real_area_sqft = 15.5 * 20\n>>> assert real_area_sqft == expected_real_area_sqft, 'real_area_sqft value is incorrect'\n>>> if real_area_sqft == expected_real_area_sqft:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real-world area calculation in square feet is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The real-world area in square feet is correctly calculated."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import numpy as np\n>>> question_id = 'scaling-the-mystery-7'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scaled_area_sqin)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_real_area_sqin = 85501200.83\n>>> res_scaled_area_sqin = np.isclose(scaled_area_sqin, expected_real_area_sqin, atol=0.001)\n>>> assert res_scaled_area_sqin, 'scaled_area_sqin value is incorrect'\n>>> if res_scaled_area_sqin:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real-world area calculation in square inches is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The real-world area in square inches is correctly calculated."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-8'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scale_ratio)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_scale_ratio = 0.022849462\n>>> res_ratio_output = abs(scale_ratio - expected_scale_ratio) < 1e-06\n>>> assert res_ratio_output, 'Scale ratio output is incorrect'\n>>> if res_ratio_output:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The scale ratio output is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The scale ratio is correctly output."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-9'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scaled_area_sqin)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> res_scaled_area_sqin = abs(scaled_area_sqin - 85501200.83044983) < 0.01\n>>> assert res_scaled_area_sqin, 'Scaled diorama area output is incorrect'\n>>> if res_scaled_area_sqin:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The scaled diorama area output is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The scaled diorama area is correctly output."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
