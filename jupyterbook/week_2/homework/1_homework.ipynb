{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# You must make sure to run all cells in sequence using shift + enter or you might encounter errors\n",
    "from pykubegrader.initialize import initialize_assignment\n",
    "\n",
    "responses = initialize_assignment(\"1_homework\", \"week_2\", \"homework\", assignment_points = 63.75, assignment_tag = 'week2-homework')\n",
    "\n",
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"1_homework.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Python Programming: Explore the Nutshell Studies üïµÔ∏è‚Äç‚ôÄÔ∏èüîç\n",
    "\n",
    "<iframe width=\"1536\" height=\"864\" src=\"https://www.youtube.com/embed/2-6ndwvK3UI\" title=\"Murder Is Her Hobby: Frances Glessner Lee and The Nutshell Studies of Unexplained Death\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "The Nutshell Studies of Unexplained Death were created by Frances Glessner Lee as miniature dioramas replicating real crime scenes. These models are used to train investigators in observing details, solving mysteries, and analyzing evidence.  \n",
    "\n",
    "![](./assets/figures/francis.png)\n",
    "\n",
    "In these Python exercises, you'll recreate parts of this fascinating process by solving problems involving data types, numerical precision, lists, dictionaries, and basic calculations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 1: Scaling the Mystery üßÆüìè\n",
    "\n",
    "![](./assets/figures/nutshell-1.jpg)\n",
    "\n",
    "\"Everything must be scaled to perfection!\"\n",
    "\n",
    "The Nutshell Studies require precise scaling to recreate scenes. You are given:\n",
    "- The real room width is 15.5 feet.\n",
    "- The model room width is given as a string: `\"4.25\"` inches.\n",
    "\n",
    "#### Tasks:\n",
    "1. Convert the room width and length to inches. Save the results in variables `room_width_inches` and `room_length_inches`.\n",
    "2. Convert the variable `model_width` to a float, replace the original variable. To do this you should use the `float()` function.\n",
    "3. Calculate the scale ratio by dividing the room width by the model width. Save the result in a variable `scale_ratio`.\n",
    "4. Calculate the real-world area:\n",
    "   - Compute the real-world area of the rectangular room using the formula:  \n",
    "     $$\n",
    "     \\text{Real-world area} = \\text{width (in feet)} \\times \\text{length (in feet)}\n",
    "     $$\n",
    "   - This will give the area in square feet.\n",
    "   - Save the result in a variable `real_area_sqft`.\n",
    "\n",
    "5. Calculate the scaled diorama area:\n",
    "   - First, calculate the area of the real room in square inches by using the width and length in inches and multiplying them.\n",
    "   - Scale this area down using the square of the scale ratio:  \n",
    "     $$\n",
    "     \\text{Scaled diorama area} = \\frac{\\text{Real area (in square inches)}}{(\\text{scale ratio})^2}\n",
    "     $$\n",
    "  - Save the result in a variable `scaled_area_sqin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "def question_1():\n",
    "    # Given information\n",
    "    # Room dimensions\n",
    "    room_width_feet = 15.5  # Real room width in feet\n",
    "    room_length_feet = 20   # Real room length in feet\n",
    "    model_width = \"4.25\"  # Model width as a string\n",
    "\n",
    "    # Convert dimensions to inches for consistency\n",
    "    ...\n",
    "\n",
    "    # Convert the model width to a float\n",
    "    ...\n",
    "\n",
    "    # Calculate the scale ratio\n",
    "    ...\n",
    "\n",
    "    # Real-world area (in square feet) and scaled diorama area (in square inches)\n",
    "    ...\n",
    "\n",
    "    return room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin\n",
    "\n",
    "\n",
    "# We have provided this code for you to test your implementation\n",
    "room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n",
    "\n",
    "# Print results\n",
    "print(f\"Scale of the model: {scale_ratio:.6f}\")\n",
    "print(f\"Real-world area: {real_area_sqft:.2f} square feet\")\n",
    "print(f\"Scaled diorama area: {scaled_area_sqin:.2f} square inches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"scaling-the-mystery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 2: Cataloging Crime Scene Objects üìùüî™\n",
    "\n",
    "![](./assets/figures/nutshell-2.jpg)\n",
    "\n",
    "\"What‚Äôs in the crime scene?\"\n",
    "\n",
    "A crime scene contains various objects: `\"knife\"`, `\"glass\"`, `\"rug\"`, `\"chair\"`, and `\"lamp\"`.  \n",
    "To investigate, you'll need to create and modify a list.\n",
    "\n",
    "#### Tasks:\n",
    "1. Build a list of object, `objects`, containing the objects mentioned above. \n",
    "    - make sure to add a comment saying `List of objects found at the crime scene`.\n",
    "2. Add three more objects: `\"hat\"`, `\"pen\"`, `\"rope\"`.\n",
    "    - There are several ways to add items to a list. You can use the `append()` method or the `+` operator.\n",
    "\n",
    "\n",
    "3. Calculate the number of objects at the crime scene and save the result in a variable `total_objects`. To do this, use the `len()` function.\n",
    "\n",
    "3. Retrieve and print the 3rd, 5th, and last objects from the list.\n",
    "    - Retrieve the third object and assign it to the variable `third_object`.\n",
    "    - Retrieve the fifth object and assign it to the variable `fifth_object`.\n",
    "    - Retrieve the last object and assign it to the variable `last_object`. Make sure this will always get the last object, regardless of the number of objects in the list, by using the index `-1`.\n",
    "\n",
    "4. Write the code to print information: \n",
    "    - The updated list of objects, \"Updated list of objects: [list of objects]\".\n",
    "    - The total number of objects, \"Total number of objects: [total_objects]\".\n",
    "    - The third object, \"3rd object: [third_object]\".\n",
    "    - The fifth object, \"5th object: [fifth_object]\".\n",
    "    - The last object, \"Last object: [last_object]\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "def question_2():\n",
    "    # List of objects in the crime scene\n",
    "    # Build a list of object, `objects`, with the following objects: \"knife\", \"glass\", \"rug\", \"chair\", \"lamp\"\n",
    "    ...\n",
    "\n",
    "    # Add three more objects: `\"hat\"`, `\"pen\"`, `\"rope\"`.\n",
    "    ...\n",
    "\n",
    "    # Calculate the total number of objects using the `len()` function\n",
    "    ...\n",
    "\n",
    "    # Retrieve specific objects\n",
    "\n",
    "    # Retrieve the third object and assign it to the variable `third_object`.\n",
    "    ...\n",
    "\n",
    "    # Retrieve the fifth object and assign it to the variable `fifth_object`.\n",
    "    ...\n",
    "\n",
    "    # Retrieve the last object and assign it to the variable `last_object`.\n",
    "    ...\n",
    "        \n",
    "    # The updated list of objects, \"Updated list of objects: [list of objects]\". \n",
    "    ...\n",
    "\n",
    "    # The total number of objects, \"Total number of objects: [total_objects]\".\n",
    "    ...\n",
    "\n",
    "    # The third object, \"3rd object: [third_object]\".\n",
    "    ...\n",
    "\n",
    "    # The fifth object, \"5th object: [fifth_object]\".\n",
    "    ...\n",
    "\n",
    "    # The last object, \"Last object: [last_object]\".\n",
    "    ...\n",
    "    \n",
    "    return objects, total_objects, third_object, fifth_object, last_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"cataloging-crime-scenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 3: Object Details Dictionary üóÇÔ∏èüîç\n",
    "\n",
    "![](./assets/figures/nutshell-3.jpg)\n",
    "\n",
    "\"Track every detail!\"\n",
    "\n",
    "Each object in the Nutshell diorama has attributes like its position, whether it‚Äôs a clue, and its priority for solving the case.\n",
    "\n",
    "### Tasks:\n",
    "1. Create a dictionary with the following details (this should be a nested dictionary):\n",
    "   - knife: position = `\"near victim's hand\"`, is_clue = `True`, priority = `8`\n",
    "   - glass: position = `\"on the table\"`, is_clue = `False`, priority = `3`\n",
    "   - rug: position = `\"center of the room\"`, is_clue = `False`, priority = `2`\n",
    "   - lamp: position = `\"overturned near the corner\"`, is_clue = `True`, priority = `6`\n",
    "2. Update the priority of `\"glass\"` to `7`.  \n",
    "3. Retrieve and print the position and priority of the `\"knife\"` and `\"rug\"`. Save the knife position and priority in variables `knife_position` and `knife_priority`, and the rug position and priority in variables `rug_position` and `rug_priority`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def question_3():\n",
    "    # Dictionary of objects with details\n",
    "    #     1. Create a dictionary with the following details (this should be a nested dictionary):\n",
    "    #    - **knife**: position = `\"near victim's hand\"`, is_clue = `True`, priority = `8`\n",
    "    #    - **glass**: position = `\"on the table\"`, is_clue = `False`, priority = `3`\n",
    "    #    - **rug**: position = `\"center of the room\"`, is_clue = `False`, priority = `2`\n",
    "    #    - **lamp**: position = `\"overturned near the corner\"`, is_clue = `True`, priority = `6`\n",
    "    ...\n",
    "\n",
    "    # Do not modify this code, it is used for grading\n",
    "    original_details = copy.deepcopy(objects_details)\n",
    "\n",
    "    # Update the priority of the \"glass\"\n",
    "    # 2. Update the **priority** of `\"glass\"` to `7`.\n",
    "    ...\n",
    "\n",
    "    # Retrieve details for \"knife\" and \"rug\"\n",
    "    # 3. Retrieve and print the **position** and **priority** of the `\"knife\"` and `\"rug\"`.\n",
    "    # Save the knife position and priority in variables `knife_position` and `knife_priority`,\n",
    "    # and the rug position and priority in variables `rug_position` and `rug_priority`.\n",
    "    ...\n",
    "    \n",
    "    return (\n",
    "        original_details, \n",
    "        objects_details,\n",
    "        knife_position,\n",
    "        knife_priority,\n",
    "        rug_position,\n",
    "        rug_priority,\n",
    "    )\n",
    "\n",
    "original_details, objects_details, knife_position, knife_priority, rug_position, rug_priority = question_3()\n",
    "\n",
    "# Print results\n",
    "print(\"Updated dictionary:\", objects_details)\n",
    "print(\"\\nDetails of knife:\")\n",
    "print(\"Position:\", knife_position)\n",
    "print(\"Priority:\", knife_priority)\n",
    "print(\"\\nDetails of rug:\")\n",
    "print(\"Position:\", rug_position)\n",
    "print(\"Priority:\", rug_priority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"Object-Details-Dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Bonus Challenge: Handling Missing Objects üïµÔ∏è‚Äç‚ôÇÔ∏è‚ùì\n",
    "\n",
    "![](./assets/figures/nutshell-4.webp)\n",
    "\n",
    "The investigators occasionally encounter missing data for certain objects in the crime scene. Use dictionary methods like `.get()` to safely handle cases where some objects might not exist in the dictionary.\n",
    "\n",
    "### Scenario:\n",
    "The following objects and their priority scores are provided:\n",
    "- knife: priority = 8\n",
    "- glass: priority = 7\n",
    "- rug: priority = 2\n",
    "- lamp: priority = 6\n",
    "\n",
    "An investigator asks about the priority of the following objects:\n",
    "1. knife\n",
    "2. hat (not in the dictionary)\n",
    "3. rug\n",
    "4. book (not in the dictionary)\n",
    "\n",
    "### Tasks:\n",
    "1. Use the `.get()` method to retrieve the priorities of the requested objects.  \n",
    "2. Assign a default priority of `0` for any objects not found in the dictionary.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "def bonus():\n",
    "\n",
    "    # Dictionary of objects with their priority scores\n",
    "    priority_scores = {\n",
    "        \"knife\": 8,\n",
    "        \"glass\": 7,\n",
    "        \"rug\": 2,\n",
    "        \"lamp\": 6\n",
    "    }\n",
    "\n",
    "    # Use the `.get()` method to safely retrieve priorities, with a default value of 0 for missing objects\n",
    "    # Save the retrieved priorities in variables knife_priority, hat_priority, rug_priority, and book_priority\n",
    "    ...\n",
    "    \n",
    "    return knife_priority, hat_priority, rug_priority, book_priority\n",
    "\n",
    "knife_priority, hat_priority, rug_priority, book_priority = bonus()\n",
    "\n",
    "# Print the retrieved priorities\n",
    "print(\"Retrieved priority scores:\")\n",
    "print(f\"Knife: {knife_priority}\")\n",
    "print(f\"Hat: {hat_priority}\")\n",
    "print(f\"Rug: {rug_priority}\")\n",
    "print(f\"Book: {book_priority}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"handeling-missing-objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\n",
    "    \"https://americanart.si.edu/exhibitions/nutshells/inside\",\n",
    "    width=800,\n",
    "    height=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Submitting Assignment\n",
    "\n",
    "Please run the following block of code using `shift + enter` to submit your assignment, you should see your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.submit.submit_assignment import submit_assignment\n",
    "\n",
    "submit_assignment(\"week2-homework\", \"1_homework\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engr131_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "Object-Details-Dictionary": {
     "name": "Object-Details-Dictionary",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-2'\n>>> max_score = 2.0\n>>> score = 0\n>>> responses = update_responses(question_id, objects_details['glass']['priority'])\n>>> _, objects_details, _, _, _, _ = question_3()\n>>> glass_priority = objects_details['glass']['priority']\n>>> assert glass_priority == 7, \"The priority of 'glass' should be updated to 7.\"\n>>> if glass_priority == 7:\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"glass\" was not correctly updated to 7.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "The priority of \"glass\" is correctly updated to 7."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'Object-Details-Dictionary-7'\n>>> max_score = 3.0\n>>> score = 0\n>>> responses = update_responses(question_id, objects_details)\n>>> _, objects_details, _, _, _, _ = question_3()\n>>> expected_final_objects_details = {'knife': {'position': \"near victim's hand\", 'is_clue': True, 'priority': 8}, 'glass': {'position': 'on the table', 'is_clue': False, 'priority': 7}, 'rug': {'position': 'center of the room', 'is_clue': False, 'priority': 2}, 'lamp': {'position': 'overturned near the corner', 'is_clue': True, 'priority': 6}}\n>>> assert objects_details == expected_final_objects_details, 'The final dictionary structure is incorrect after updates.'\n>>> if objects_details == expected_final_objects_details:\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The final dictionary structure is incorrect after updates.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "The final dictionary structure is correct after updates."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "cataloging-crime-scenes": {
     "name": "cataloging-crime-scenes",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> max_question_points = str(25.25)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(63.75)\n>>> log_variable('total-points', f'Reading-Week-X, 1_homework', 63.75)\n>>> question_id = 'cataloging-crime-scenes-1'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> objects, _, _, _, _ = question_2()\n>>> sys.output = sys.__stdout__\n>>> assert 'knife' in objects and 'glass' in objects and ('rug' in objects) and ('chair' in objects) and ('lamp' in objects), 'The initial list is incorrect.'\n>>> if 'knife' in objects and 'glass' in objects and ('rug' in objects) and ('chair' in objects) and ('lamp' in objects):\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The initial list of objects is missing or incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The initial list of objects is created correctly."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> question_id = 'cataloging-crime-scenes-2'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> objects, _, _, _, _ = question_2()\n>>> sys.stdout = sys.__stdout__\n>>> assert 'hat' in objects and 'pen' in objects and ('rope' in objects), 'New objects were not added correctly.'\n>>> if 'hat' in objects and 'pen' in objects and ('rope' in objects):\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The new objects are not added correctly.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "New objects are added correctly to the list."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> question_id = 'cataloging-crime-scenes-3'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> _, total_objects, _, _, _ = question_2()\n>>> sys.stdout = sys.__stdout__\n>>> assert total_objects == 8, f'Total objects should be 8, but got {total_objects}.'\n>>> if total_objects == 8:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The total number of objects is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The total number of objects is calculated correctly."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import sys\n>>> import io\n>>> question_id = 'cataloging-crime-scenes-4'\n>>> max_score = 3.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> _, _, third_object, fifth_object, last_object = question_2()\n>>> sys.stdout = sys.__stdout__\n>>> assert third_object == 'rug', f\"The third object should be 'rug', but got {third_object}.\"\n>>> assert fifth_object == 'lamp', f\"The fifth object should be 'lamp', but got {fifth_object}.\"\n>>> assert last_object == 'rope', f\"The last object should be 'rope', but got {last_object}.\"\n>>> if third_object == 'rug' and fifth_object == 'lamp' and (last_object == 'rope'):\n...     score = 3.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Retrieval of specific objects is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 3.5,
         "success_message": "Retrieval of specific objects is correct."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import io\n>>> import sys\n>>> question_id = 'cataloging-crime-scenes-5'\n>>> max_score = 1.5\n>>> score = 0\n>>> output = io.StringIO()\n>>> sys.stdout = output\n>>> question_2()\n>>> sys.stdout = sys.__stdout__\n>>> output_str = output.getvalue()\n>>> assert 'Updated list of objects:' in output_str, 'The updated list of objects is not printed correctly.'\n>>> assert 'Total number of objects: 8' in output_str, 'The total number of objects is not printed correctly.'\n>>> assert '3rd object: rug' in output_str, 'The third object is not printed correctly.'\n>>> assert '5th object: lamp' in output_str, 'The fifth object is not printed correctly.'\n>>> assert 'Last object: rope' in output_str, 'The last object is not printed correctly.'\n>>> if 'Updated list of objects:' in output_str and 'Total number of objects: 8' in output_str and ('3rd object: rug' in output_str) and ('5th object: lamp' in output_str) and ('Last object: rope' in output_str):\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The printed outputs are incorrect or missing.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The printed outputs are formatted correctly."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "handeling-missing-objects": {
     "name": "handeling-missing-objects",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'handeling-missing-objects-2'\n>>> max_score = 1.0\n>>> score = 0\n>>> responses = update_responses(question_id, hat_priority)\n>>> _, hat_priority, _, _ = bonus()\n>>> assert hat_priority == 0, \"The priority of 'hat' should default to 0.\"\n>>> if hat_priority == 0:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"hat\" should default to 0 when missing.",
         "hidden": false,
         "locked": false,
         "points": 1.0,
         "success_message": "The default priority of \"hat\" is correctly set to 0."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'handeling-missing-objects-4'\n>>> max_score = 1.0\n>>> score = 0\n>>> responses = update_responses(question_id, book_priority)\n>>> _, _, _, book_priority = bonus()\n>>> assert book_priority == 0, \"The priority of 'book' should default to 0.\"\n>>> if book_priority == 0:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The priority of \"book\" should default to 0 when missing.",
         "hidden": false,
         "locked": false,
         "points": 1.0,
         "success_message": "The default priority of \"book\" is correctly set to 0."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "scaling-the-mystery": {
     "name": "scaling-the-mystery",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> max_question_points = str(13.5)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(63.75)\n>>> log_variable('total-points', f'Reading-Week-X, 1_homework', 63.75)\n>>> question_id = 'scaling-the-mystery-1'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(model_width)))\n>>> responses = update_responses(question_id, model_width)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> modal_width_float = isinstance(model_width, float)\n>>> assert modal_width_float, 'model_width must be a float'\n>>> assert model_width == 4.25, 'model_width value should be 4.25 after conversion'\n>>> if modal_width_float and model_width == 4.25:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The model width string must be converted to a float.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The model width string is correctly converted to a float."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-2'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, room_width_inches)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_room_width_inches = 15.5 * 12\n>>> assert room_width_inches == expected_room_width_inches, 'room_width_inches value is incorrect'\n>>> if room_width_inches == expected_room_width_inches:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real room width conversion to inches is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "Real room width is correctly converted to inches."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import re\n>>> import inspect\n>>> question_id = 'scaling-the-mystery-3'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, room_width_inches)\n>>> function_source = inspect.getsource(question_1)\n>>> condition = re.findall('.*float\\\\(model_width\\\\).*', function_source)\n>>> assert condition, 'You must convert the model width to a float, using the float() function.'\n>>> if condition:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The model width string must be converted to a float.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The model width string is correctly converted to a float."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-4'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, room_length_inches)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_room_length_inches = 20 * 12\n>>> assert room_length_inches == expected_room_length_inches, 'room_length_inches value is incorrect'\n>>> if room_length_inches == expected_room_length_inches:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real room length conversion to inches is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "Real room length is correctly converted to inches."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-5'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scale_ratio)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_scale_ratio = 4.25 / (15.5 * 12)\n>>> assert scale_ratio == expected_scale_ratio, 'scale_ratio value is incorrect'\n>>> if scale_ratio == expected_scale_ratio:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The scale ratio calculation is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The scale ratio is correctly calculated."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-6'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, real_area_sqft)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_real_area_sqft = 15.5 * 20\n>>> assert real_area_sqft == expected_real_area_sqft, 'real_area_sqft value is incorrect'\n>>> if real_area_sqft == expected_real_area_sqft:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real-world area calculation in square feet is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The real-world area in square feet is correctly calculated."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import numpy as np\n>>> question_id = 'scaling-the-mystery-7'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scaled_area_sqin)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_real_area_sqin = 85501200.83\n>>> res_scaled_area_sqin = np.isclose(scaled_area_sqin, expected_real_area_sqin, atol=0.001)\n>>> assert res_scaled_area_sqin, 'scaled_area_sqin value is incorrect'\n>>> if res_scaled_area_sqin:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Real-world area calculation in square inches is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The real-world area in square inches is correctly calculated."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-8'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scale_ratio)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> expected_scale_ratio = 0.022849462\n>>> res_ratio_output = abs(scale_ratio - expected_scale_ratio) < 1e-06\n>>> assert res_ratio_output, 'Scale ratio output is incorrect'\n>>> if res_ratio_output:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The scale ratio output is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The scale ratio is correctly output."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'scaling-the-mystery-9'\n>>> max_score = 1.5\n>>> score = 0\n>>> responses = update_responses(question_id, scaled_area_sqin)\n>>> room_width_inches, room_length_inches, model_width, scale_ratio, real_area_sqft, scaled_area_sqin = question_1()\n>>> res_scaled_area_sqin = abs(scaled_area_sqin - scaled_area_sqin) < 0.01\n>>> assert res_scaled_area_sqin, 'Scaled diorama area output is incorrect'\n>>> if res_scaled_area_sqin:\n...     score = 1.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_homework', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The scaled diorama area output is incorrect.",
         "hidden": false,
         "locked": false,
         "points": 1.5,
         "success_message": "The scaled diorama area is correctly output."
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
