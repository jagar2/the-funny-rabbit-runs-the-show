{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# You must make sure to run all cells in sequence using shift + enter or you might encounter errors\n",
    "from pykubegrader.initialize import initialize_assignment\n",
    "\n",
    "responses = initialize_assignment(\"1_practice_midterm_q\", \"week_6\", \"PracticeMidterm\", assignment_points = 143.0, assignment_tag = 'week6-PracticeMidterm')\n",
    "\n",
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"1_practice_midterm_q.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# â“ ENGR131: Introduction to Programming for Engineers\n",
    "## Practice Midterm Exam\n",
    "\n",
    "The practice midterm is designed to help you prepare for the actual midterm exam. It is designed to be similar in format and difficulty to the actual exam. The practice exam is graded and counts as 10% bonus points towards your  midterm exam grade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For the multiple choice questions it is expected that you have access to a python interpreter. Do not go at it alone, use the resources available to you to help you answer the questions. Without the interpreter some of the questions may be difficult to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_practice_midterm_q import Question1\n",
    "Question1().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_practice_midterm_q import Question2\n",
    "Question2().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_practice_midterm_q import Question3\n",
    "Question3().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Engineering Component Tracker: Loops, Continue, Break, Dictionaries, and Lists\n",
    "\n",
    "### Instructions:\n",
    "You are managing the assembly of a robotic arm. Each component of the arm is represented as a dictionary, where the keys are component IDs (e.g., \"A1\") and the values are dictionaries containing component details. Your task is to write a function `process_components()` that processes a list of components using loops, `continue`, and `break`. The task involves multiple steps that can be graded individually.\n",
    "\n",
    "## Engineering Component Tracker: Loops, Continue, Break, Dictionaries, and Lists\n",
    "\n",
    "### Instructions:\n",
    "You are managing the assembly of a robotic arm. Each component of the arm is represented as a dictionary, where the keys are component IDs (e.g., \"A1\") and the values are dictionaries containing component details. Your task is to write a function `process_components()` that processes a list of components using loops, `continue`, and `break`. The task involves multiple steps that can be graded individually.\n",
    " \n",
    " ### Requirements:\n",
    " 1. **Input:** The function receives a list of dictionaries, each representing a component:\n",
    " \n",
    "            | id  | status | weight |\n",
    "            |-----|--------|--------|\n",
    "            | A1  | ok     | 3.5    |\n",
    "            | B2  | ok     | 2.0    |\n",
    "            | C3  | error  | 4.1    |\n",
    "            | D4  | ok     | 1.2    |\n",
    " 2. **Part 1:** Count the components with status \"ok\" using a loop and return the count.\n",
    " 3. **Part 2:** Skip components with status \"error\", and create a list of IDs for valid components.\n",
    " 4. **Part 3:** If a component's weight exceeds 4.0, break the loop and return \"Overweight component detected!\".\n",
    " 5. **Part 4:** Return a dictionary summarizing the count of \"ok\" components, the valid IDs list, and the break message (if triggered).\n",
    " \n",
    " ### Helpful Information:\n",
    " - Use a loop to iterate through the `components` list.\n",
    " - Use `continue` to skip certain iterations based on a condition.\n",
    " - Use `break` to exit the loop early when another condition is met.\n",
    " - Remember that you can access dictionary values using the syntax `dictionary[key]`.\n",
    " - Example methods:\n",
    "   - `append`: Add an element to a list.\n",
    "\n",
    "We provide detailed inline instructions for each part of the task. Please read the instructions carefully and complete each part accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# define a function `process_components` that takes a dictionary of components as input\n",
    "...\n",
    "    \n",
    "    # Initialize variables\n",
    "    # create a variable `ok_count` and set it to 0\n",
    "    # create a variable `valid_ids` and set it to an empty list\n",
    "    # create a variable `break_message` and set it to None\n",
    "    ...\n",
    "\n",
    "    # Loop through components\n",
    "    ...\n",
    "    \n",
    "        # Part 3: Check for overweight components\n",
    "        # if the component's weight is greater than 4.0, set `break_message` to \"Overweight component detected!\" and break the loop\n",
    "        ...\n",
    "        \n",
    "        # Part 2: Skip components with status \"error\"\n",
    "        # if the component's status is \"error\", continue to the next iteration\n",
    "        ...\n",
    "\n",
    "        # Part 1: Count components with status \"ok\"\n",
    "        # if the component's status is \"ok\", increment `ok_count` by 1 and append the component's id to `valid_ids`\n",
    "        ...\n",
    "        \n",
    "    # Part 4: Return the results as a dictionary\n",
    "    # return a dictionary with keys \"ok_count\", \"valid_ids\", and \"break_message\" and their corresponding values\n",
    "    ...\n",
    "\n",
    "# Example usage\n",
    "# write the component dictionary based on the table provided\n",
    "...\n",
    "\n",
    "# Call the function with the components dictionary and store the result in a variable `result`\n",
    "# You can print the results function to check if it's working correctly\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"loops-and-dictionaries-engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Symbolic Computation with SymPy\n",
    "\n",
    "### Instructions:\n",
    "You are working with symbolic mathematics in Python using SymPy. Your task is to define and visualize an equation symbolically.\n",
    "\n",
    "### Requirements:\n",
    "1. **Part 1:** Define symbolic variables \\( x \\) and \\( y \\).\n",
    "2. **Part 2:** Construct the equation:\n",
    "\n",
    "$$\n",
    "(x^2 + y^2 - 1)^3 - x^2 y^3 = 0\n",
    "$$\n",
    "\n",
    "3. **Part 3:** Use `sympy.plot_implicit` to visualize the heart shape. We do not expect you to know how to use this function. You should use one of the several methods shown in class to read the docstring. \n",
    "4. **Part 4:** Return the equation and the plot object.\n",
    "\n",
    "### Helpful Information:\n",
    "- Make sure you import from sympy symbols, Eq, and from sympy.plotting plot_implicit.\n",
    "- Use `symbols` from SymPy to define \\( x \\) and \\( y \\).\n",
    "- Use `Eq` to represent the equation.\n",
    "- Use `plot_implicit` to visualize the heart shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Import required functions from sympy\n",
    "...\n",
    "\n",
    "# Define symbolic variables\n",
    "...\n",
    "\n",
    "# Construct the heart-shaped equation\n",
    "...\n",
    "\n",
    "# Plot the equation\n",
    "...\n",
    "\n",
    "# do not modify below this line\n",
    "# this is used for grading\n",
    "def get_equation():\n",
    "    return eq, plot\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"symbolic-heart-curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Numerical Computing with NumPy: Prime Number Checker ğŸ”¢\n",
    "\n",
    "### Instructions:\n",
    "You are working with numerical data and need to determine which numbers in a given NumPy array are prime. Your task is to write a function `find_primes()` that takes a NumPy array of integers and returns a boolean array indicating which elements are prime.\n",
    " \n",
    " ### Requirements:\n",
    " 1. The function receives a NumPy array of positive integers.\n",
    " 2.  Implement an efficient prime-checking function using NumPy.\n",
    " 4. The function should return a boolean NumPy array of the same shape as the input, where `True` represents a prime number and `False` represents a non-prime.\n",
    " \n",
    " ### Helpful Information:\n",
    " - A prime number is a natural number greater than **1** that has only two divisors: **1 and itself**.\n",
    " - The first few primes are: **2, 3, 5, 7, 11, 13, ...**\n",
    " - The function should handle edge cases like `0` and `1` correctly (they are not prime).\n",
    "\n",
    " We will provide inline instructions for each part of the task. Please read the instructions carefully and complete each part accordingly.\n",
    "\n",
    " Make sure to include docstring and comments in your code to explain the logic and purpose of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# import numpy use the common alias np\n",
    "...\n",
    "\n",
    "# Define the function `find_primes`\n",
    "...\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \"\"\"\n",
    "    # Ensure input is a NumPy array, to do this convert the input to a NumPy array using `np.asarray`\n",
    "    # Override the input variable `arr` with the NumPy array\n",
    "    ...\n",
    "    \n",
    "    # Initialize a boolean array `is_prime` with the same shape as the input array\n",
    "    # Set all values to `True` initially\n",
    "    # You can use the `np.ones_like` function to initialize the array, make sure to set the `dtype` to `bool`\n",
    "    ...\n",
    "\n",
    "    # Mark 0 and 1 as non-prime\n",
    "    # Use indexing to set the values at indices less than 2 to `False`\n",
    "    ...\n",
    "\n",
    "    # The trick to finding primes is to mark multiples of each number as non-prime\n",
    "    # Loop through numbers starting from 2 up to the square root of the maximum number in the array\n",
    "    # Use the `np.sqrt` function to calculate the square root\n",
    "    # Use the `int` function to convert the result to an integer -- make sure to add 1 to the result\n",
    "    # Use the `range` function to loop through the numbers\n",
    "    # Write your for loop here\n",
    "    ...\n",
    "        # Create a boolean mask to identify multiples of the current number\n",
    "        # These are the numbers that are divisible by the current number but not equal to the current number\n",
    "        ...\n",
    "        \n",
    "        # Mark multiples as non-prime by setting the corresponding values in `is_prime` to `False`\n",
    "        ...\n",
    "\n",
    "    # Return the boolean array `is_prime`\n",
    "    ...\n",
    "\n",
    "# Example usage:\n",
    "test_array = np.array([0, 1, 2, 3, 4, 5, 10, 11, 13, 15, 17])\n",
    "prime_results = find_primes(test_array)\n",
    "print(prime_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"numpy-prime-check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## String Processing with Sliding Window: Longest Unique Substring ğŸ” \n",
    "\n",
    "### Instructions:\n",
    "You are given a string `s` containing lowercase and uppercase English letters, digits, and special characters. Your task is to implement a function `length_of_longest_substring()` that returns the **length of the longest substring** without repeating characters.\n",
    "\n",
    "This question is designed to test your understanding of algorithmic thinking. You can solve this problem using any approach you prefer, but we recommend using the sliding window technique for efficiency.\n",
    "\n",
    "### Requirements:\n",
    "1. **Input:** The function receives a string `s`.\n",
    "2.  Ensure that the function correctly tracks character positions to prevent repetition.\n",
    "3.  Return an integer representing the maximum length of a substring without repeating characters.\n",
    "\n",
    "### Helpful Information:\n",
    "- A **substring** is a contiguous sequence of characters within a string.\n",
    "- You should might want to use a  **dictionary** to store the last seen index of characters.\n",
    "- Use the **sliding window** approach to efficiently check substrings.\n",
    "- Ideally the function should work well for very large strings.\n",
    "\n",
    "### Viable logic\n",
    "\n",
    "1. Define a dictionary to store the last seen index of characters. The key is the character, and the value is the index.\n",
    "2. Store the max length of  all substrings found so far.\n",
    "3. Store the start index, the left pointer of a window in the string. \n",
    "4. Iterate through the string, it is helpful to use the enumerate function to get the index and character.\n",
    "5. If the character is in the dictionary, and the character's index is greater than the start index, update the start index to the character's index + 1.\n",
    "6. Update the character's index in the dictionary, to the last seen index.\n",
    "7. Use the max function to update the max length of all substrings found so far, this is either the current max value, or the length of the current substring. \n",
    "8. Return the max length of all substrings after traversing the string.\n",
    "\n",
    "The goal is to go through character by character, and keep track of the last seen index of each character. If a character is repeated then move the left pointer to the right by one so there are no repeating characters in the substring. If the distance between the left pointer and the current character is greater than the current max length, update the max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# Example usage:\n",
    "test_string = \"abcabcbb\"\n",
    "result = length_of_longest_substring(test_string)\n",
    "print(result)  # Expected output: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"longest-unique-substring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Submitting Assignment\n",
    "\n",
    "Please run the following block of code using `shift + enter` to submit your assignment, you should see your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.submit.submit_assignment import submit_assignment\n",
    "\n",
    "submit_assignment(\"week6-PracticeMidterm\", \"1_practice_midterm_q\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engr131_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "longest-unique-substring": {
     "name": "longest-unique-substring",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> max_question_points = str(24.0)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(79.0)\n>>> log_variable('total-points', f'Reading-Week-X, 1_practice_midterm_q', 79.0)\n>>> question_id = 'longest-unique-substring-1'\n>>> max_score = 1.0\n>>> score = 0\n>>> function_exists = callable(length_of_longest_substring)\n>>> assert function_exists, 'The function `length_of_longest_substring` must be defined and callable.'\n>>> if (function_exists, 'The function `length_of_longest_substring` must be defined and callable.'):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(function_exists))\n",
         "failure_message": "Failed: The function `length_of_longest_substring` is not defined correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `length_of_longest_substring` exists and is callable!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-2'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = 'abcabcbb'\n>>> expected_output = 3\n>>> basic_test_results = length_of_longest_substring(test_input)\n>>> assert basic_test_results == expected_output, f'Expected {expected_output}, but got {basic_test_results}.'\n>>> if (basic_test_results == expected_output, f'Expected {expected_output}, but got {basic_test_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(basic_test_results))\n",
         "failure_message": "Failed: The function does not correctly compute longest unique substrings.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly identifies longest unique substrings!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-3'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = 'abcdefg'\n>>> expected_output = 7\n>>> unique_test_results = length_of_longest_substring(test_input)\n>>> assert unique_test_results == expected_output, f'Expected {expected_output}, but got {unique_test_results}.'\n>>> if (unique_test_results == expected_output, f'Expected {expected_output}, but got {unique_test_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(unique_test_results))\n",
         "failure_message": "Failed: The function does not correctly handle a string with all unique characters.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles all unique characters!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-4'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = 'bbbbb'\n>>> expected_output = 1\n>>> repeated_test_results = length_of_longest_substring(test_input)\n>>> assert repeated_test_results == expected_output, f'Expected {expected_output}, but got {repeated_test_results}.'\n>>> if (repeated_test_results == expected_output, f'Expected {expected_output}, but got {repeated_test_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(repeated_test_results))\n",
         "failure_message": "Failed: The function does not correctly identify longest substrings when characters repeat.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles repeated characters!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-5'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = 'aAabcABC'\n>>> expected_output = 6\n>>> mixed_case_test_results = length_of_longest_substring(test_input)\n>>> assert mixed_case_test_results == expected_output, f'Expected {expected_output}, but got {mixed_case_test_results}.'\n>>> if (mixed_case_test_results == expected_output, f'Expected {expected_output}, but got {mixed_case_test_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(mixed_case_test_results))\n",
         "failure_message": "Failed: The function does not correctly handle mixed uppercase and lowercase characters.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles mixed-case input!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-6'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = 'ab!@#ab!@#'\n>>> expected_output = 5\n>>> special_char_test_results = length_of_longest_substring(test_input)\n>>> assert special_char_test_results == expected_output, f'Expected {expected_output}, but got {special_char_test_results}.'\n>>> if (special_char_test_results == expected_output, f'Expected {expected_output}, but got {special_char_test_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(special_char_test_results))\n",
         "failure_message": "Failed: The function does not correctly identify substrings with special characters.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles strings with special characters!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-7'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = 'abcdefghijklmnopqrstuvwxyz' * 1000\n>>> expected_output = 26\n>>> long_test_results = length_of_longest_substring(test_input)\n>>> assert long_test_results == expected_output, f'Expected {expected_output}, but got {long_test_results}.'\n>>> if (long_test_results == expected_output, f'Expected {expected_output}, but got {long_test_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(long_test_results))\n",
         "failure_message": "Failed: The function is too slow for long inputs.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles long strings efficiently!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-8'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_input = ''\n>>> expected_output = 0\n>>> empty_string_results = length_of_longest_substring(test_input)\n>>> assert empty_string_results == expected_output, f'Expected {expected_output}, but got {empty_string_results}.'\n>>> if (empty_string_results == expected_output, f'Expected {expected_output}, but got {empty_string_results}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(empty_string_results))\n",
         "failure_message": "Failed: The function does not handle empty strings correctly.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly handles an empty string!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'longest-unique-substring-9'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = 'z'\n>>> expected_output = 1\n>>> single_char_results = length_of_longest_substring(test_input)\n>>> assert single_char_results == expected_output, f'Expected {expected_output}, but got {single_char_results}.'\n>>> if (single_char_results == expected_output, f'Expected {expected_output}, but got {single_char_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(single_char_results))\n",
         "failure_message": "Failed: The function does not correctly handle single-character strings.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles single-character strings!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "loops-and-dictionaries-engineering": {
     "name": "loops-and-dictionaries-engineering",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> max_question_points = str(22.0)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(79.0)\n>>> log_variable('total-points', f'Reading-Week-X, 1_practice_midterm_q', 79.0)\n>>> question_id = 'loops-and-dictionaries-engineering-1'\n>>> max_score = 1.0\n>>> score = 0\n>>> function_exists = callable(process_components)\n>>> assert function_exists, 'The function `process_components` must be defined and callable.'\n>>> if (function_exists, 'The function `process_components` must be defined and callable.'):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(function_exists))\n",
         "failure_message": "Failed: The function `process_components` is not defined correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `process_components` exists and is callable!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> import inspect\n>>> import re\n>>> question_id = 'loops-and-dictionaries-engineering-2'\n>>> max_score = 2.0\n>>> score = 0\n>>> code = inspect.getsource(process_components)\n>>> ok_count_init = re.search('ok_count\\\\s*=\\\\s*0', code)\n>>> valid_ids_init = re.search('valid_ids\\\\s*=\\\\s*\\\\[\\\\]', code)\n>>> break_message_init = re.search('break_message\\\\s*=\\\\s*None', code)\n>>> initial_values = all([ok_count_init, valid_ids_init, break_message_init])\n>>> assert initial_values, 'Expected variables `ok_count = 0`, `valid_ids = []`, and `break_message = None` in the function.'\n>>> if (initial_values, 'Expected variables `ok_count = 0`, `valid_ids = []`, and `break_message = None` in the function.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(initial_values))\n",
         "failure_message": "Failed: One or more of `ok_count`, `valid_ids`, or `break_message` are not initialized properly.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: `ok_count`, `valid_ids`, and `break_message` are initialized correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> import re\n>>> import inspect\n>>> question_id = 'loops-and-dictionaries-engineering-3'\n>>> max_score = 2.0\n>>> score = 0\n>>> code = inspect.getsource(process_components)\n>>> loop_check = re.search(\"\\n    for\\\\s+          # 'for' keyword followed by one or more spaces\\n    component\\\\s+    # 'component' variable followed by one or more spaces\\n    in\\\\s+           # 'in' keyword followed by one or more spaces\\n    components\\\\s*   # 'components' variable followed by zero or more spaces\\n    :               # colon\\n    \", code, re.IGNORECASE | re.VERBOSE)\n>>> assert loop_check, 'Expected a loop with `for component in components:` to iterate over the dictionary.'\n>>> if (loop_check, 'Expected a loop with `for component in components:` to iterate over the dictionary.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: The function does not correctly iterate over `components`.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function iterates over `components` correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'loops-and-dictionaries-engineering-4'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_components = [{'id': 'X1', 'status': 'ok', 'weight': 3.0}, {'id': 'X2', 'status': 'ok', 'weight': 5.1}, {'id': 'X3', 'status': 'ok', 'weight': 2.5}]\n>>> result = process_components(test_components)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfYnJlYWtfbWVzc2FnZSA9ICJPdmVyd2VpZ2h0IGNvbXBvbmVudCBkZXRlY3RlZCEi').decode())\n>>> exec(base64.b64decode('YnJlYWtfbWVzc2FnZSA9IHJlc3VsdFsiYnJlYWtfbWVzc2FnZSJd').decode())\n>>> assert break_message == expected_break_message, f\"Expected `break_message` to be '{expected_break_message}', but got '{break_message}'.\"\n>>> if (break_message == expected_break_message, f\"Expected `break_message` to be '{expected_break_message}', but got '{break_message}'.\"):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(break_message))\n",
         "failure_message": "Failed: Overweight components are not handled correctly.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly detects overweight components and stops processing!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'loops-and-dictionaries-engineering-5'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_components = [{'id': 'Y1', 'status': 'ok', 'weight': 2.0}, {'id': 'Y2', 'status': 'error', 'weight': 3.0}, {'id': 'Y3', 'status': 'ok', 'weight': 1.5}]\n>>> result = process_components(test_components)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb2tfY291bnQgPSAy').decode())\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfdmFsaWRfaWRzID0gWyJZMSIsICJZMyJd').decode())\n>>> ok_count = result['ok_count']\n>>> valid_ids = result['valid_ids']\n>>> assert result['ok_count'] == expected_ok_count, f'Expected `ok_count` to be {expected_ok_count}, but got {result['ok_count']}.'\n>>> assert result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'\n>>> if (result['ok_count'] == expected_ok_count, f'Expected `ok_count` to be {expected_ok_count}, but got {result['ok_count']}.') and (result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(ok_count))\n>>> responses = update_responses(question_id, str(valid_ids))\n",
         "failure_message": "Failed: The function does not skip `error` components correctly.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly skips components with `status='error'`!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'loops-and-dictionaries-engineering-6'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_components = [{'id': 'Z1', 'status': 'ok', 'weight': 2.5}, {'id': 'Z2', 'status': 'ok', 'weight': 3.8}, {'id': 'Z3', 'status': 'ok', 'weight': 2.1}]\n>>> result = process_components(test_components)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb2tfY291bnQgPSAz').decode())\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfdmFsaWRfaWRzID0gWyJaMSIsICJaMiIsICJaMyJd').decode())\n>>> ok_count = result['ok_count']\n>>> valid_ids = result['valid_ids']\n>>> assert result['ok_count'] == expected_ok_count, f'Expected `ok_count` to be {expected_ok_count}, but got {result['ok_count']}.'\n>>> assert result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'\n>>> if (result['ok_count'] == expected_ok_count, f'Expected `ok_count` to be {expected_ok_count}, but got {result['ok_count']}.') and (result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(ok_count))\n>>> responses = update_responses(question_id, str(valid_ids))\n",
         "failure_message": "Failed: The function does not correctly count `ok` components or append their IDs.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly counts `ok` components and stores their IDs!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'loops-and-dictionaries-engineering-7'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_components = [{'id': 'A1', 'status': 'ok', 'weight': 2.0}]\n>>> result = process_components(test_components)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfa2V5cyA9IHsib2tfY291bnQiLCAidmFsaWRfaWRzIiwgImJyZWFrX21lc3NhZ2UifQ==').decode())\n>>> result_keys = set(result.keys())\n>>> assert result_keys == expected_keys, f'Expected keys {expected_keys}, but got {result_keys}.'\n>>> if (result_keys == expected_keys, f'Expected keys {expected_keys}, but got {result_keys}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(result_keys))\n",
         "failure_message": "Failed: The function does not return a dictionary with the expected keys.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function returns a correctly structured dictionary!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'loops-and-dictionaries-engineering-8'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_components = []\n>>> result = process_components(test_components)\n>>> ok_count = result['ok_count']\n>>> valid_ids = result['valid_ids']\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfcmVzdWx0ID0gewoib2tfY291bnQiOiAwLAoidmFsaWRfaWRzIjogW10sCiJicmVha19tZXNzYWdlIjogTm9uZSwKfQ==').decode())\n>>> assert result == expected_result, f'Expected result {expected_result}, but got {result}.'\n>>> if (result == expected_result, f'Expected result {expected_result}, but got {result}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(result))\n",
         "failure_message": "Failed: The function does not handle an empty list correctly.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly handles an empty components list!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'loops-and-dictionaries-engineering-9'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_components = [{'id': 'DUP1', 'status': 'ok', 'weight': 2.0}, {'id': 'DUP1', 'status': 'ok', 'weight': 3.0}, {'id': 'DUP2', 'status': 'ok', 'weight': 1.5}]\n>>> result = process_components(test_components)\n>>> valid_ids = result['valid_ids']\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfdmFsaWRfaWRzID0gWyJEVVAxIiwgIkRVUDEiLCAiRFVQMiJdICAjIElEcyBzaG91bGQgYmUgYXBwZW5kZWQgYXMgdGhleSBhcHBlYXI=').decode())\n>>> assert result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'\n>>> if (result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(valid_ids))\n",
         "failure_message": "Failed: The function does not handle duplicate component IDs correctly.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly processes duplicate component IDs!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'loops-and-dictionaries-engineering-10'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_components = [{'id': 'W1', 'status': 'ok', 'weight': 4.0}, {'id': 'W2', 'status': 'ok', 'weight': 3.9}]\n>>> result = process_components(test_components)\n>>> ok_count = result['ok_count']\n>>> valid_ids = result['valid_ids']\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb2tfY291bnQgPSAy').decode())\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfdmFsaWRfaWRzID0gWyJXMSIsICJXMiJd').decode())\n>>> assert result['ok_count'] == expected_ok_count, f'Expected `ok_count` to be {expected_ok_count}, but got {result['ok_count']}.'\n>>> assert result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'\n>>> if (result['ok_count'] == expected_ok_count, f'Expected `ok_count` to be {expected_ok_count}, but got {result['ok_count']}.') and (result['valid_ids'] == expected_valid_ids, f'Expected `valid_ids` to be {expected_valid_ids}, but got {result['valid_ids']}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(ok_count))\n>>> responses = update_responses(question_id, str(valid_ids))\n",
         "failure_message": "Failed: The function incorrectly excludes components at exactly 4.0 weight.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly allows components at the weight limit!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "numpy-prime-check": {
     "name": "numpy-prime-check",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> max_question_points = str(25.0)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(79.0)\n>>> log_variable('total-points', f'Reading-Week-X, 1_practice_midterm_q', 79.0)\n>>> question_id = 'numpy-prime-check-1'\n>>> max_score = 1.0\n>>> score = 0\n>>> function_exists = callable(find_primes)\n>>> assert function_exists, 'The function `find_primes` must be defined and callable.'\n>>> if (function_exists, 'The function `find_primes` must be defined and callable.'):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(function_exists))\n",
         "failure_message": "Failed: The function `find_primes` is not defined correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `find_primes` exists and is callable!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-2'\n>>> max_score = 1.0\n>>> score = 0\n>>> docstring_exists = find_primes.__doc__ is not None\n>>> docstring_word_count = len(find_primes.__doc__.split()) if docstring_exists else 0\n>>> assert docstring_exists and docstring_word_count >= 8, f'The function `find_primes` must have a docstring with at least 8 words. Current docstring word count: {docstring_word_count}'\n>>> if (docstring_exists and docstring_word_count >= 8, f'The function `find_primes` must have a docstring with at least 8 words. Current docstring word count: {docstring_word_count}'):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(docstring_exists))\n>>> responses = update_responses(question_id, str(docstring_word_count))\n",
         "failure_message": "Failed: The function `find_primes` does not have a docstring with at least 8 words.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `find_primes` has a docstring with at least 8 words."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-3'\n>>> max_score = 2.0\n>>> score = 0\n>>> input_data = [0, 1, 2, 3, 4, 5, 10, 11, 13, 15, 17]\n>>> output_results = find_primes(input_data)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfcmVzdWx0cyA9IG5wLmFycmF5KApbRmFsc2UsIEZhbHNlLCBUcnVlLCBUcnVlLCBGYWxzZSwgVHJ1ZSwgRmFsc2UsIFRydWUsIFRydWUsIEZhbHNlLCBUcnVlXQop').decode())\n>>> assert np.array_equal(output_results, expected_results), f'Expected {expected_results}, but got {output_results}'\n>>> if np.array_equal(output_results, expected_results):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(input_data))\n>>> responses = update_responses(question_id, str(output_results))\n",
         "failure_message": "Failed: The function `find_primes` does not work correctly with non-array input.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function `find_primes` works correctly with non-array input."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-4'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_input = np.array([2, 3, 5, 7, 11])\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb3V0cHV0ID0gbnAuYXJyYXkoW1RydWUsIFRydWUsIFRydWUsIFRydWUsIFRydWVdKQ==').decode())\n>>> prime_test_results = find_primes(test_input)\n>>> assert np.array_equal(prime_test_results, expected_output), f'Expected {expected_output}, but got {prime_test_results}.'\n>>> if (np.array_equal(prime_test_results, expected_output), f'Expected {expected_output}, but got {prime_test_results}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(prime_test_results))\n",
         "failure_message": "Failed: The function does not correctly identify prime numbers.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly identifies small prime numbers!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-5'\n>>> max_score = 1.0\n>>> score = 0\n>>> test_array = np.array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30])\n>>> prime_results = find_primes(test_array)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfcmVzdWx0cyA9IG5wLmFycmF5KApbRmFsc2UsIEZhbHNlLCBGYWxzZSwgVHJ1ZSwgRmFsc2UsIEZhbHNlLCBGYWxzZSwgRmFsc2UsIEZhbHNlLCBUcnVlLCBGYWxzZV0KKQ==').decode())\n>>> assert np.array_equal(prime_results, expected_results), f'Expected {expected_results}, but got {prime_results}'\n>>> if np.array_equal(prime_results, expected_results):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(test_array))\n>>> responses = update_responses(question_id, str(prime_results))\n",
         "failure_message": "Failed: The function `find_primes` does not correctly identify prime numbers in a larger array.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `find_primes` correctly identifies prime numbers in a larger array."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-6'\n>>> max_score = 1.0\n>>> score = 0\n>>> test_array = np.array([0, 1, 4, 6, 8, 9, 10])\n>>> prime_results = find_primes(test_array)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfcmVzdWx0cyA9IG5wLmFycmF5KFtGYWxzZSwgRmFsc2UsIEZhbHNlLCBGYWxzZSwgRmFsc2UsIEZhbHNlLCBGYWxzZV0p').decode())\n>>> assert np.array_equal(prime_results, expected_results), f'Expected {expected_results}, but got {prime_results}'\n>>> if np.array_equal(prime_results, expected_results):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(test_array))\n>>> responses = update_responses(question_id, str(prime_results))\n",
         "failure_message": "Failed: The function `find_primes` does not handle edge cases correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `find_primes` handles edge cases correctly."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-7'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_input = np.array([4, 6, 8, 9, 10, 12])\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb3V0cHV0ID0gbnAuYXJyYXkoW0ZhbHNlLCBGYWxzZSwgRmFsc2UsIEZhbHNlLCBGYWxzZSwgRmFsc2VdKQ==').decode())\n>>> composite_test_results = find_primes(test_input)\n>>> assert np.array_equal(composite_test_results, expected_output), f'Expected {expected_output}, but got {composite_test_results}.'\n>>> if (np.array_equal(composite_test_results, expected_output), f'Expected {expected_output}, but got {composite_test_results}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(composite_test_results))\n",
         "failure_message": "Failed: The function incorrectly classifies composite numbers as prime.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly identifies composite numbers!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-8'\n>>> max_score = 2.0\n>>> score = 0\n>>> test_input = np.array([0, 1, -1, -5, -10])\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb3V0cHV0ID0gbnAuYXJyYXkoW0ZhbHNlLCBGYWxzZSwgRmFsc2UsIEZhbHNlLCBGYWxzZV0p').decode())\n>>> edge_case_results = find_primes(test_input)\n>>> assert np.array_equal(edge_case_results, expected_output), f'Expected {expected_output}, but got {edge_case_results}.'\n>>> if (np.array_equal(edge_case_results, expected_output), f'Expected {expected_output}, but got {edge_case_results}.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(edge_case_results))\n",
         "failure_message": "Failed: The function does not correctly handle edge cases.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly handles edge cases (0, 1, negatives)!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-9'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = np.array([101, 103, 107, 109, 113, 200, 201, 202, 203])\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb3V0cHV0ID0gbnAuYXJyYXkoW1RydWUsIFRydWUsIFRydWUsIFRydWUsIFRydWUsIEZhbHNlLCBGYWxzZSwgRmFsc2UsIEZhbHNlXSk=').decode())\n>>> large_number_results = find_primes(test_input)\n>>> assert np.array_equal(large_number_results, expected_output), f'Expected {expected_output}, but got {large_number_results}.'\n>>> if (np.array_equal(large_number_results, expected_output), f'Expected {expected_output}, but got {large_number_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(large_number_results))\n",
         "failure_message": "Failed: The function does not efficiently handle large numbers.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles large numbers!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-10'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = np.array([[2, 3, 4], [5, 6, 7]])\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfc2hhcGUgPSB0ZXN0X2lucHV0LnNoYXBl').decode())\n>>> shape_test_results = find_primes(test_input).shape\n>>> assert shape_test_results == expected_shape, f'Expected shape {expected_shape}, but got {shape_test_results}.'\n>>> if (shape_test_results == expected_shape, f'Expected shape {expected_shape}, but got {shape_test_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(shape_test_results))\n",
         "failure_message": "Failed: The function does not preserve the shape of the input array.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function maintains NumPy array shape!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-11'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = np.array([[29, 30, 31], [32, 33, 34]])\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb3V0cHV0ID0gbnAuYXJyYXkoW1tUcnVlLCBGYWxzZSwgVHJ1ZV0sIFtGYWxzZSwgRmFsc2UsIEZhbHNlXV0p').decode())\n>>> large_2d_results = find_primes(test_input)\n>>> assert np.array_equal(large_2d_results, expected_output), f'Expected {expected_output}, but got {large_2d_results}.'\n>>> if (np.array_equal(large_2d_results, expected_output), f'Expected {expected_output}, but got {large_2d_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(large_2d_results))\n",
         "failure_message": "Failed: The function does not correctly process 2D arrays.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function correctly handles large 2D arrays!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-12'\n>>> max_score = 1.0\n>>> score = 0\n>>> test_array = np.array([7])\n>>> prime_results = find_primes(test_array)\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfcmVzdWx0cyA9IG5wLmFycmF5KFtUcnVlXSk=').decode())\n>>> assert np.array_equal(prime_results, expected_results), f'Expected {expected_results}, but got {prime_results}'\n>>> if np.array_equal(prime_results, expected_results):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(test_array))\n>>> responses = update_responses(question_id, str(prime_results))\n",
         "failure_message": "Failed: The function `find_primes` does not correctly identify a single prime number.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `find_primes` correctly identifies a single prime number."
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> question_id = 'numpy-prime-check-13'\n>>> max_score = 3.0\n>>> score = 0\n>>> test_input = np.array([1000003, 1000033, 1000037, 1000039, 1000000, 1000001])\n>>> exec(base64.b64decode('ZXhwZWN0ZWRfb3V0cHV0ID0gbnAuYXJyYXkoW1RydWUsIFRydWUsIFRydWUsIFRydWUsIEZhbHNlLCBGYWxzZV0p').decode())\n>>> huge_number_results = find_primes(test_input)\n>>> assert np.array_equal(huge_number_results, expected_output), f'Expected {expected_output}, but got {huge_number_results}.'\n>>> if (np.array_equal(huge_number_results, expected_output), f'Expected {expected_output}, but got {huge_number_results}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(huge_number_results))\n",
         "failure_message": "Failed: The function does not efficiently process very large numbers.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The function efficiently handles very large numbers!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "symbolic-heart-curve": {
     "name": "symbolic-heart-curve",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> max_question_points = str(8.0)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(79.0)\n>>> log_variable('total-points', f'Reading-Week-X, 1_practice_midterm_q', 79.0)\n>>> question_id = 'symbolic-heart-curve-1'\n>>> max_score = 1.0\n>>> score = 0\n>>> function_exists = callable(get_equation)\n>>> assert function_exists, 'The function `get_equation` must be defined and callable.'\n>>> if (function_exists, 'The function `get_equation` must be defined and callable.'):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(function_exists))\n",
         "failure_message": "Failed: The function `get_equation` is not defined correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: The function `get_equation` exists and is callable!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> result = get_equation()\n>>> heart_eq_returned = result[0]\n>>> from sympy import Eq\n>>> question_id = 'symbolic-heart-curve-2'\n>>> max_score = 2.0\n>>> score = 0\n>>> exec(base64.b64decode('aXNfZXEgPSBpc2luc3RhbmNlKGhlYXJ0X2VxX3JldHVybmVkLCBFcSk=').decode())\n>>> assert is_eq, 'Expected a SymPy `Eq` equation as the first return value.'\n>>> if (is_eq, 'Expected a SymPy `Eq` equation as the first return value.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(is_eq))\n",
         "failure_message": "Failed: The function does not return a valid SymPy equation.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly returns a SymPy equation!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> import sympy\n>>> result = get_equation()\n>>> heart_plot_returned = result[1]\n>>> from sympy.plotting.plot import Plot\n>>> question_id = 'symbolic-heart-curve-3'\n>>> max_score = 2.0\n>>> score = 0\n>>> exec(base64.b64decode('aXNfcGxvdCA9IGlzaW5zdGFuY2UoaGVhcnRfcGxvdF9yZXR1cm5lZCwgUGxvdCk=').decode())\n>>> assert is_plot, 'Expected a SymPy `Plot` object as the second return value.'\n>>> if (is_plot, 'Expected a SymPy `Plot` object as the second return value.'):\n...     score = 2.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(is_plot))\n",
         "failure_message": "Failed: The function does not return a valid SymPy plot object.",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Success: The function correctly returns a SymPy plot object!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from sympy import Eq\n>>> question_id = 'symbolic-heart-curve-4'\n>>> max_score = 3.0\n>>> score = 0\n>>> expected_equation = Eq((x ** 2 + y ** 2 - 1) ** 3 - x ** 2 * y ** 3, 0)\n>>> result = get_equation()\n>>> heart_eq_returned = result[0]\n>>> matches_equation = heart_eq_returned == expected_equation\n>>> assert matches_equation, f'Expected the equation to be {expected_equation}, but got {heart_eq_returned}.'\n>>> if (matches_equation, f'Expected the equation to be {expected_equation}, but got {heart_eq_returned}.'):\n...     score = 3.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_practice_midterm_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(matches_equation))\n",
         "failure_message": "Failed: The heart equation is not correctly defined.",
         "hidden": false,
         "locked": false,
         "points": 3,
         "success_message": "Success: The heart equation matches the expected symbolic expression!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
